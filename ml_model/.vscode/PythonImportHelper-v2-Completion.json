[
    {
        "label": "joblib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "joblib",
        "description": "joblib",
        "detail": "joblib",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "onnx",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "onnx",
        "description": "onnx",
        "detail": "onnx",
        "documentation": {}
    },
    {
        "label": "skl2onnx",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "skl2onnx",
        "description": "skl2onnx",
        "detail": "skl2onnx",
        "documentation": {}
    },
    {
        "label": "convert_sklearn",
        "importPath": "skl2onnx",
        "description": "skl2onnx",
        "isExtraImport": true,
        "detail": "skl2onnx",
        "documentation": {}
    },
    {
        "label": "FloatTensorType",
        "importPath": "skl2onnx.common.data_types",
        "description": "skl2onnx.common.data_types",
        "isExtraImport": true,
        "detail": "skl2onnx.common.data_types",
        "documentation": {}
    },
    {
        "label": "prepare",
        "importPath": "onnx_tf.backend",
        "description": "onnx_tf.backend",
        "isExtraImport": true,
        "detail": "onnx_tf.backend",
        "documentation": {}
    },
    {
        "label": "tensorflow",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tensorflow",
        "description": "tensorflow",
        "detail": "tensorflow",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "seaborn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "seaborn",
        "description": "seaborn",
        "detail": "seaborn",
        "documentation": {}
    },
    {
        "label": "Sequential",
        "importPath": "tensorflow.keras.models",
        "description": "tensorflow.keras.models",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models",
        "documentation": {}
    },
    {
        "label": "Dense",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Dropout",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Adam",
        "importPath": "tensorflow.keras.optimizers",
        "description": "tensorflow.keras.optimizers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.optimizers",
        "documentation": {}
    },
    {
        "label": "EarlyStopping",
        "importPath": "tensorflow.keras.callbacks",
        "description": "tensorflow.keras.callbacks",
        "isExtraImport": true,
        "detail": "tensorflow.keras.callbacks",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "mean_absolute_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "mean_squared_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "r2_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "mean_absolute_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "mean_squared_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "r2_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "mean_absolute_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "mean_squared_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "r2_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "mean_absolute_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "mean_squared_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "r2_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "mean_absolute_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "mean_squared_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "r2_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "mean_absolute_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "mean_squared_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "r2_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "DecisionTreeRegressor",
        "importPath": "sklearn.tree",
        "description": "sklearn.tree",
        "isExtraImport": true,
        "detail": "sklearn.tree",
        "documentation": {}
    },
    {
        "label": "xgboost",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "xgboost",
        "description": "xgboost",
        "detail": "xgboost",
        "documentation": {}
    },
    {
        "label": "lightgbm",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "lightgbm",
        "description": "lightgbm",
        "detail": "lightgbm",
        "documentation": {}
    },
    {
        "label": "RandomForestRegressor",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "LinearRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "convert_to_onnx",
        "description": "convert_to_onnx",
        "peekOfCode": "model = joblib.load(\"house_price_model.pkl\")\nscaler = joblib.load(\"scaler.pkl\")\n# Define input type\ninput_features = [(\"float_input\", FloatTensorType([None, 4]))]  # 4 features: sqft, bath, balcony, bhk\n# Convert to ONNX format with explicit target opset\nonnx_model = convert_sklearn(\n    model, \n    initial_types=input_features,\n    target_opset=9  # Explicitly set to opset 9\n)",
        "detail": "convert_to_onnx",
        "documentation": {}
    },
    {
        "label": "scaler",
        "kind": 5,
        "importPath": "convert_to_onnx",
        "description": "convert_to_onnx",
        "peekOfCode": "scaler = joblib.load(\"scaler.pkl\")\n# Define input type\ninput_features = [(\"float_input\", FloatTensorType([None, 4]))]  # 4 features: sqft, bath, balcony, bhk\n# Convert to ONNX format with explicit target opset\nonnx_model = convert_sklearn(\n    model, \n    initial_types=input_features,\n    target_opset=9  # Explicitly set to opset 9\n)\n# Save ONNX model",
        "detail": "convert_to_onnx",
        "documentation": {}
    },
    {
        "label": "input_features",
        "kind": 5,
        "importPath": "convert_to_onnx",
        "description": "convert_to_onnx",
        "peekOfCode": "input_features = [(\"float_input\", FloatTensorType([None, 4]))]  # 4 features: sqft, bath, balcony, bhk\n# Convert to ONNX format with explicit target opset\nonnx_model = convert_sklearn(\n    model, \n    initial_types=input_features,\n    target_opset=9  # Explicitly set to opset 9\n)\n# Save ONNX model\nwith open(\"house_price_model.onnx\", \"wb\") as f:\n    f.write(onnx_model.SerializeToString())",
        "detail": "convert_to_onnx",
        "documentation": {}
    },
    {
        "label": "onnx_model",
        "kind": 5,
        "importPath": "convert_to_onnx",
        "description": "convert_to_onnx",
        "peekOfCode": "onnx_model = convert_sklearn(\n    model, \n    initial_types=input_features,\n    target_opset=9  # Explicitly set to opset 9\n)\n# Save ONNX model\nwith open(\"house_price_model.onnx\", \"wb\") as f:\n    f.write(onnx_model.SerializeToString())\n# Optional: Validate the ONNX model\ntry:",
        "detail": "convert_to_onnx",
        "documentation": {}
    },
    {
        "label": "onnx_model",
        "kind": 5,
        "importPath": "convert_to_tfl",
        "description": "convert_to_tfl",
        "peekOfCode": "onnx_model = onnx.load(\"house_price_model.onnx\")\n# Convert the ONNX model to a TensorFlow model\ntf_rep = prepare(onnx_model)\ntf_rep.export_graph(\"house_price_model.pb\")\n# Convert the TensorFlow model to TFLite format\nconverter = tf.lite.TFLiteConverter.from_saved_model(\"house_price_model.pb\")\ntflite_model = converter.convert()\n# Save the TFLite model to file\nwith open(\"house_price_model.tflite\", \"wb\") as f:\n    f.write(tflite_model)",
        "detail": "convert_to_tfl",
        "documentation": {}
    },
    {
        "label": "tf_rep",
        "kind": 5,
        "importPath": "convert_to_tfl",
        "description": "convert_to_tfl",
        "peekOfCode": "tf_rep = prepare(onnx_model)\ntf_rep.export_graph(\"house_price_model.pb\")\n# Convert the TensorFlow model to TFLite format\nconverter = tf.lite.TFLiteConverter.from_saved_model(\"house_price_model.pb\")\ntflite_model = converter.convert()\n# Save the TFLite model to file\nwith open(\"house_price_model.tflite\", \"wb\") as f:\n    f.write(tflite_model)\nprint(\"Model conversion to TFLite successful!\")",
        "detail": "convert_to_tfl",
        "documentation": {}
    },
    {
        "label": "converter",
        "kind": 5,
        "importPath": "convert_to_tfl",
        "description": "convert_to_tfl",
        "peekOfCode": "converter = tf.lite.TFLiteConverter.from_saved_model(\"house_price_model.pb\")\ntflite_model = converter.convert()\n# Save the TFLite model to file\nwith open(\"house_price_model.tflite\", \"wb\") as f:\n    f.write(tflite_model)\nprint(\"Model conversion to TFLite successful!\")",
        "detail": "convert_to_tfl",
        "documentation": {}
    },
    {
        "label": "tflite_model",
        "kind": 5,
        "importPath": "convert_to_tfl",
        "description": "convert_to_tfl",
        "peekOfCode": "tflite_model = converter.convert()\n# Save the TFLite model to file\nwith open(\"house_price_model.tflite\", \"wb\") as f:\n    f.write(tflite_model)\nprint(\"Model conversion to TFLite successful!\")",
        "detail": "convert_to_tfl",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "df = pd.read_csv(\"data/Bengaluru_House_Data.csv\")\n# Data Cleaning: Remove missing values\ndf = df.dropna()\n# Keep only rows where 'total_sqft' is numeric\ndf = df[df['total_sqft'].apply(lambda x: str(x).replace('.', '').isdigit())]\ndf['total_sqft'] = df['total_sqft'].astype(float)\n# Convert 'size' to numeric by extracting the number (e.g., \"2 BHK\" -> 2)\nif 'size' in df.columns:\n    df['size'] = df['size'].str.extract(r\"(\\d+)\").astype(float)\n# Define features and target",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "df = df.dropna()\n# Keep only rows where 'total_sqft' is numeric\ndf = df[df['total_sqft'].apply(lambda x: str(x).replace('.', '').isdigit())]\ndf['total_sqft'] = df['total_sqft'].astype(float)\n# Convert 'size' to numeric by extracting the number (e.g., \"2 BHK\" -> 2)\nif 'size' in df.columns:\n    df['size'] = df['size'].str.extract(r\"(\\d+)\").astype(float)\n# Define features and target\nfeatures = ['total_sqft', 'bath', 'balcony', 'size']\ntarget = 'price'",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "df = df[df['total_sqft'].apply(lambda x: str(x).replace('.', '').isdigit())]\ndf['total_sqft'] = df['total_sqft'].astype(float)\n# Convert 'size' to numeric by extracting the number (e.g., \"2 BHK\" -> 2)\nif 'size' in df.columns:\n    df['size'] = df['size'].str.extract(r\"(\\d+)\").astype(float)\n# Define features and target\nfeatures = ['total_sqft', 'bath', 'balcony', 'size']\ntarget = 'price'\n# Ensure dataframe contains only the desired columns\ndf = df[features + [target]]",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "df['total_sqft']",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "df['total_sqft'] = df['total_sqft'].astype(float)\n# Convert 'size' to numeric by extracting the number (e.g., \"2 BHK\" -> 2)\nif 'size' in df.columns:\n    df['size'] = df['size'].str.extract(r\"(\\d+)\").astype(float)\n# Define features and target\nfeatures = ['total_sqft', 'bath', 'balcony', 'size']\ntarget = 'price'\n# Ensure dataframe contains only the desired columns\ndf = df[features + [target]]\n# Split data into training and testing sets",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "features = ['total_sqft', 'bath', 'balcony', 'size']\ntarget = 'price'\n# Ensure dataframe contains only the desired columns\ndf = df[features + [target]]\n# Split data into training and testing sets\nX = df[features]\ny = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale features (important for neural networks)\nscaler = StandardScaler()",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "target",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "target = 'price'\n# Ensure dataframe contains only the desired columns\ndf = df[features + [target]]\n# Split data into training and testing sets\nX = df[features]\ny = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale features (important for neural networks)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "df = df[features + [target]]\n# Split data into training and testing sets\nX = df[features]\ny = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale features (important for neural networks)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# Save the scaler for later use",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "X",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "X = df[features]\ny = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale features (important for neural networks)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# Save the scaler for later use\njoblib.dump(scaler, \"scaler.pkl\")\n# ================================",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "y = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale features (important for neural networks)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# Save the scaler for later use\njoblib.dump(scaler, \"scaler.pkl\")\n# ================================\n# Custom Neural Network Model",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "scaler",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# Save the scaler for later use\njoblib.dump(scaler, \"scaler.pkl\")\n# ================================\n# Custom Neural Network Model\n# ================================\n# Hyperparameters (feel free to modify these)\nn_hidden_layers = 3           # Number of hidden layers",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "X_train_scaled",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "X_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# Save the scaler for later use\njoblib.dump(scaler, \"scaler.pkl\")\n# ================================\n# Custom Neural Network Model\n# ================================\n# Hyperparameters (feel free to modify these)\nn_hidden_layers = 3           # Number of hidden layers\nneurons_per_layer = 64        # Number of neurons in each hidden layer",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "X_test_scaled",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "X_test_scaled = scaler.transform(X_test)\n# Save the scaler for later use\njoblib.dump(scaler, \"scaler.pkl\")\n# ================================\n# Custom Neural Network Model\n# ================================\n# Hyperparameters (feel free to modify these)\nn_hidden_layers = 3           # Number of hidden layers\nneurons_per_layer = 64        # Number of neurons in each hidden layer\ndropout_rate = 0.2            # Dropout rate (set to 0 to disable dropout)",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "n_hidden_layers",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "n_hidden_layers = 3           # Number of hidden layers\nneurons_per_layer = 64        # Number of neurons in each hidden layer\ndropout_rate = 0.2            # Dropout rate (set to 0 to disable dropout)\nlearning_rate = 0.001         # Learning rate for the optimizer\nepochs = 100                  # Maximum number of training epochs\nbatch_size = 32               # Batch size\npatience = 10                 # Early stopping patience\n# Build the model\nmodel = Sequential()\n# Input layer",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "neurons_per_layer",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "neurons_per_layer = 64        # Number of neurons in each hidden layer\ndropout_rate = 0.2            # Dropout rate (set to 0 to disable dropout)\nlearning_rate = 0.001         # Learning rate for the optimizer\nepochs = 100                  # Maximum number of training epochs\nbatch_size = 32               # Batch size\npatience = 10                 # Early stopping patience\n# Build the model\nmodel = Sequential()\n# Input layer\nmodel.add(Dense(neurons_per_layer, activation='relu', input_dim=X_train_scaled.shape[1]))",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "dropout_rate",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "dropout_rate = 0.2            # Dropout rate (set to 0 to disable dropout)\nlearning_rate = 0.001         # Learning rate for the optimizer\nepochs = 100                  # Maximum number of training epochs\nbatch_size = 32               # Batch size\npatience = 10                 # Early stopping patience\n# Build the model\nmodel = Sequential()\n# Input layer\nmodel.add(Dense(neurons_per_layer, activation='relu', input_dim=X_train_scaled.shape[1]))\nif dropout_rate > 0:",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "learning_rate",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "learning_rate = 0.001         # Learning rate for the optimizer\nepochs = 100                  # Maximum number of training epochs\nbatch_size = 32               # Batch size\npatience = 10                 # Early stopping patience\n# Build the model\nmodel = Sequential()\n# Input layer\nmodel.add(Dense(neurons_per_layer, activation='relu', input_dim=X_train_scaled.shape[1]))\nif dropout_rate > 0:\n    model.add(Dropout(dropout_rate))",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "epochs",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "epochs = 100                  # Maximum number of training epochs\nbatch_size = 32               # Batch size\npatience = 10                 # Early stopping patience\n# Build the model\nmodel = Sequential()\n# Input layer\nmodel.add(Dense(neurons_per_layer, activation='relu', input_dim=X_train_scaled.shape[1]))\nif dropout_rate > 0:\n    model.add(Dropout(dropout_rate))\n# Additional hidden layers",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "batch_size",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "batch_size = 32               # Batch size\npatience = 10                 # Early stopping patience\n# Build the model\nmodel = Sequential()\n# Input layer\nmodel.add(Dense(neurons_per_layer, activation='relu', input_dim=X_train_scaled.shape[1]))\nif dropout_rate > 0:\n    model.add(Dropout(dropout_rate))\n# Additional hidden layers\nfor _ in range(n_hidden_layers - 1):",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "patience",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "patience = 10                 # Early stopping patience\n# Build the model\nmodel = Sequential()\n# Input layer\nmodel.add(Dense(neurons_per_layer, activation='relu', input_dim=X_train_scaled.shape[1]))\nif dropout_rate > 0:\n    model.add(Dropout(dropout_rate))\n# Additional hidden layers\nfor _ in range(n_hidden_layers - 1):\n    model.add(Dense(neurons_per_layer, activation='relu'))",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "model = Sequential()\n# Input layer\nmodel.add(Dense(neurons_per_layer, activation='relu', input_dim=X_train_scaled.shape[1]))\nif dropout_rate > 0:\n    model.add(Dropout(dropout_rate))\n# Additional hidden layers\nfor _ in range(n_hidden_layers - 1):\n    model.add(Dense(neurons_per_layer, activation='relu'))\n    if dropout_rate > 0:\n        model.add(Dropout(dropout_rate))",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "early_stop",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "early_stop = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n# Train the model\nhistory = model.fit(\n    X_train_scaled, y_train,\n    validation_split=0.1,\n    epochs=epochs,\n    batch_size=batch_size,\n    callbacks=[early_stop],\n    verbose=1\n)",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "history",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "history = model.fit(\n    X_train_scaled, y_train,\n    validation_split=0.1,\n    epochs=epochs,\n    batch_size=batch_size,\n    callbacks=[early_stop],\n    verbose=1\n)\n# ================================\n# Evaluation",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "y_train_pred",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "y_train_pred = model.predict(X_train_scaled).flatten()\ny_test_pred = model.predict(X_test_scaled).flatten()\n# Calculate metrics\ntrain_mae = mean_absolute_error(y_train, y_train_pred)\ntest_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Custom NN Model - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "y_test_pred",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "y_test_pred = model.predict(X_test_scaled).flatten()\n# Calculate metrics\ntrain_mae = mean_absolute_error(y_train, y_train_pred)\ntest_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Custom NN Model - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Custom NN Model - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "train_mae",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "train_mae = mean_absolute_error(y_train, y_train_pred)\ntest_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Custom NN Model - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Custom NN Model - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"Custom NN Model - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save the Keras model",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "test_mae",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "test_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Custom NN Model - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Custom NN Model - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"Custom NN Model - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save the Keras model\nmodel.save(\"custom_nn_house_price_model.h5\")",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "train_rmse",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Custom NN Model - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Custom NN Model - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"Custom NN Model - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save the Keras model\nmodel.save(\"custom_nn_house_price_model.h5\")\nprint(\"Custom Neural Network model training complete! Saved as 'custom_nn_house_price_model.h5'.\")",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "test_rmse",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Custom NN Model - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Custom NN Model - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"Custom NN Model - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save the Keras model\nmodel.save(\"custom_nn_house_price_model.h5\")\nprint(\"Custom Neural Network model training complete! Saved as 'custom_nn_house_price_model.h5'.\")\n# ================================",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "train_r2",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "train_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Custom NN Model - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Custom NN Model - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"Custom NN Model - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save the Keras model\nmodel.save(\"custom_nn_house_price_model.h5\")\nprint(\"Custom Neural Network model training complete! Saved as 'custom_nn_house_price_model.h5'.\")\n# ================================\n# Additional: Confusion Metrics for Regression",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "test_r2",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "test_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Custom NN Model - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Custom NN Model - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"Custom NN Model - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save the Keras model\nmodel.save(\"custom_nn_house_price_model.h5\")\nprint(\"Custom Neural Network model training complete! Saved as 'custom_nn_house_price_model.h5'.\")\n# ================================\n# Additional: Confusion Metrics for Regression\n# ================================",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "median_price_threshold",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "median_price_threshold = df['price'].median()\ny_test_class = (y_test > median_price_threshold).astype(int)\ny_test_pred_class = (y_test_pred > median_price_threshold).astype(int)\nconf_matrix = confusion_matrix(y_test_class, y_test_pred_class)\nprint(\"\\nConfusion Matrix (Test Data):\")\nprint(conf_matrix)\nprint(\"\\nClassification Report (Test Data):\")\nprint(classification_report(y_test_class, y_test_pred_class))\n# Visualize the confusion matrix\nplt.figure(figsize=(6, 5))",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "y_test_class",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "y_test_class = (y_test > median_price_threshold).astype(int)\ny_test_pred_class = (y_test_pred > median_price_threshold).astype(int)\nconf_matrix = confusion_matrix(y_test_class, y_test_pred_class)\nprint(\"\\nConfusion Matrix (Test Data):\")\nprint(conf_matrix)\nprint(\"\\nClassification Report (Test Data):\")\nprint(classification_report(y_test_class, y_test_pred_class))\n# Visualize the confusion matrix\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "y_test_pred_class",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "y_test_pred_class = (y_test_pred > median_price_threshold).astype(int)\nconf_matrix = confusion_matrix(y_test_class, y_test_pred_class)\nprint(\"\\nConfusion Matrix (Test Data):\")\nprint(conf_matrix)\nprint(\"\\nClassification Report (Test Data):\")\nprint(classification_report(y_test_class, y_test_pred_class))\n# Visualize the confusion matrix\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.title(\"Confusion Matrix (Test Data)\")",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "conf_matrix",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "conf_matrix = confusion_matrix(y_test_class, y_test_pred_class)\nprint(\"\\nConfusion Matrix (Test Data):\")\nprint(conf_matrix)\nprint(\"\\nClassification Report (Test Data):\")\nprint(classification_report(y_test_class, y_test_pred_class))\n# Visualize the confusion matrix\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.title(\"Confusion Matrix (Test Data)\")\nplt.xlabel(\"Predicted Class\")",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "mean_price",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "mean_price = df['price'].mean()\nmedian_price = df['price'].median()\nxlims = ax.get_xlim()\nylims = ax.get_ylim()\nax.text(xlims[1]*0.6, ylims[1]*0.8, f\"Mean: {mean_price:.2f}\\nMedian: {median_price:.2f}\",\n        bbox=dict(facecolor='white', alpha=0.5))\nplt.show()\n# 2️⃣ Feature vs. Price Scatter Plots with correlation coefficients\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfor i, feature in enumerate(features):",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "median_price",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "median_price = df['price'].median()\nxlims = ax.get_xlim()\nylims = ax.get_ylim()\nax.text(xlims[1]*0.6, ylims[1]*0.8, f\"Mean: {mean_price:.2f}\\nMedian: {median_price:.2f}\",\n        bbox=dict(facecolor='white', alpha=0.5))\nplt.show()\n# 2️⃣ Feature vs. Price Scatter Plots with correlation coefficients\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfor i, feature in enumerate(features):\n    row, col = divmod(i, 2)",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "xlims",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "xlims = ax.get_xlim()\nylims = ax.get_ylim()\nax.text(xlims[1]*0.6, ylims[1]*0.8, f\"Mean: {mean_price:.2f}\\nMedian: {median_price:.2f}\",\n        bbox=dict(facecolor='white', alpha=0.5))\nplt.show()\n# 2️⃣ Feature vs. Price Scatter Plots with correlation coefficients\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfor i, feature in enumerate(features):\n    row, col = divmod(i, 2)\n    sns.scatterplot(x=df[feature], y=df['price'], ax=axes[row, col], color='red')",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "ylims",
        "kind": 5,
        "importPath": "custom_model",
        "description": "custom_model",
        "peekOfCode": "ylims = ax.get_ylim()\nax.text(xlims[1]*0.6, ylims[1]*0.8, f\"Mean: {mean_price:.2f}\\nMedian: {median_price:.2f}\",\n        bbox=dict(facecolor='white', alpha=0.5))\nplt.show()\n# 2️⃣ Feature vs. Price Scatter Plots with correlation coefficients\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfor i, feature in enumerate(features):\n    row, col = divmod(i, 2)\n    sns.scatterplot(x=df[feature], y=df['price'], ax=axes[row, col], color='red')\n    axes[row, col].set_title(f\"{feature} vs Price\")",
        "detail": "custom_model",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "df = pd.read_csv(\"data/Bengaluru_House_Data.csv\")\n# Data Cleaning\ndf = df.dropna()  # Remove missing values\n# Keep only rows where 'total_sqft' is numeric\ndf = df[df['total_sqft'].apply(lambda x: str(x).replace('.', '').isdigit())]\ndf['total_sqft'] = df['total_sqft'].astype(float)  # Convert to float\n# Convert 'size' to numeric by extracting the number (e.g., \"2 BHK\" -> 2)\nif 'size' in df.columns:\n    df['size'] = df['size'].str.extract(r\"(\\d+)\").astype(float)\n# Updated feature list",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "df = df.dropna()  # Remove missing values\n# Keep only rows where 'total_sqft' is numeric\ndf = df[df['total_sqft'].apply(lambda x: str(x).replace('.', '').isdigit())]\ndf['total_sqft'] = df['total_sqft'].astype(float)  # Convert to float\n# Convert 'size' to numeric by extracting the number (e.g., \"2 BHK\" -> 2)\nif 'size' in df.columns:\n    df['size'] = df['size'].str.extract(r\"(\\d+)\").astype(float)\n# Updated feature list\nfeatures = ['total_sqft', 'bath', 'balcony', 'size']\ntarget = 'price'",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "df = df[df['total_sqft'].apply(lambda x: str(x).replace('.', '').isdigit())]\ndf['total_sqft'] = df['total_sqft'].astype(float)  # Convert to float\n# Convert 'size' to numeric by extracting the number (e.g., \"2 BHK\" -> 2)\nif 'size' in df.columns:\n    df['size'] = df['size'].str.extract(r\"(\\d+)\").astype(float)\n# Updated feature list\nfeatures = ['total_sqft', 'bath', 'balcony', 'size']\ntarget = 'price'\n# Filter dataframe to required columns\ndf = df[features + [target]]",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "df['total_sqft']",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "df['total_sqft'] = df['total_sqft'].astype(float)  # Convert to float\n# Convert 'size' to numeric by extracting the number (e.g., \"2 BHK\" -> 2)\nif 'size' in df.columns:\n    df['size'] = df['size'].str.extract(r\"(\\d+)\").astype(float)\n# Updated feature list\nfeatures = ['total_sqft', 'bath', 'balcony', 'size']\ntarget = 'price'\n# Filter dataframe to required columns\ndf = df[features + [target]]\n# Train-Test Split",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "features = ['total_sqft', 'bath', 'balcony', 'size']\ntarget = 'price'\n# Filter dataframe to required columns\ndf = df[features + [target]]\n# Train-Test Split\nX = df[features]\ny = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale the features (optional for tree-based methods, but included for consistency)\nscaler = StandardScaler()",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "target",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "target = 'price'\n# Filter dataframe to required columns\ndf = df[features + [target]]\n# Train-Test Split\nX = df[features]\ny = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale the features (optional for tree-based methods, but included for consistency)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "df = df[features + [target]]\n# Train-Test Split\nX = df[features]\ny = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale the features (optional for tree-based methods, but included for consistency)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# ================================",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "X",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "X = df[features]\ny = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale the features (optional for tree-based methods, but included for consistency)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# ================================\n# Train Decision Tree Regressor\n# ================================",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "y = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale the features (optional for tree-based methods, but included for consistency)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# ================================\n# Train Decision Tree Regressor\n# ================================\nmodel = DecisionTreeRegressor(random_state=42)",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "scaler",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# ================================\n# Train Decision Tree Regressor\n# ================================\nmodel = DecisionTreeRegressor(random_state=42)\nmodel.fit(X_train_scaled, y_train)\n# Predictions\ny_train_pred = model.predict(X_train_scaled)",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "X_train_scaled",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "X_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# ================================\n# Train Decision Tree Regressor\n# ================================\nmodel = DecisionTreeRegressor(random_state=42)\nmodel.fit(X_train_scaled, y_train)\n# Predictions\ny_train_pred = model.predict(X_train_scaled)\ny_test_pred = model.predict(X_test_scaled)",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "X_test_scaled",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "X_test_scaled = scaler.transform(X_test)\n# ================================\n# Train Decision Tree Regressor\n# ================================\nmodel = DecisionTreeRegressor(random_state=42)\nmodel.fit(X_train_scaled, y_train)\n# Predictions\ny_train_pred = model.predict(X_train_scaled)\ny_test_pred = model.predict(X_test_scaled)\n# Model Performance Metrics",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "model = DecisionTreeRegressor(random_state=42)\nmodel.fit(X_train_scaled, y_train)\n# Predictions\ny_train_pred = model.predict(X_train_scaled)\ny_test_pred = model.predict(X_test_scaled)\n# Model Performance Metrics\ntrain_mae = mean_absolute_error(y_train, y_train_pred)\ntest_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "y_train_pred",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "y_train_pred = model.predict(X_train_scaled)\ny_test_pred = model.predict(X_test_scaled)\n# Model Performance Metrics\ntrain_mae = mean_absolute_error(y_train, y_train_pred)\ntest_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Decision Tree Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "y_test_pred",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "y_test_pred = model.predict(X_test_scaled)\n# Model Performance Metrics\ntrain_mae = mean_absolute_error(y_train, y_train_pred)\ntest_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Decision Tree Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Decision Tree Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "train_mae",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "train_mae = mean_absolute_error(y_train, y_train_pred)\ntest_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Decision Tree Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Decision Tree Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"Decision Tree Regressor - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "test_mae",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "test_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Decision Tree Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Decision Tree Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"Decision Tree Regressor - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler\njoblib.dump(model, \"house_price_decision_tree_model.pkl\")",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "train_rmse",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Decision Tree Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Decision Tree Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"Decision Tree Regressor - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler\njoblib.dump(model, \"house_price_decision_tree_model.pkl\")\njoblib.dump(scaler, \"scaler.pkl\")",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "test_rmse",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Decision Tree Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Decision Tree Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"Decision Tree Regressor - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler\njoblib.dump(model, \"house_price_decision_tree_model.pkl\")\njoblib.dump(scaler, \"scaler.pkl\")\nprint(\"Decision Tree model training complete! Saved as 'house_price_decision_tree_model.pkl'.\")",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "train_r2",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "train_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Decision Tree Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Decision Tree Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"Decision Tree Regressor - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler\njoblib.dump(model, \"house_price_decision_tree_model.pkl\")\njoblib.dump(scaler, \"scaler.pkl\")\nprint(\"Decision Tree model training complete! Saved as 'house_price_decision_tree_model.pkl'.\")\n# ================================",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "test_r2",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "test_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Decision Tree Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Decision Tree Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"Decision Tree Regressor - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler\njoblib.dump(model, \"house_price_decision_tree_model.pkl\")\njoblib.dump(scaler, \"scaler.pkl\")\nprint(\"Decision Tree model training complete! Saved as 'house_price_decision_tree_model.pkl'.\")\n# ================================\n# Additional: Confusion Metrics for Regression",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "median_price_threshold",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "median_price_threshold = df['price'].median()\ny_test_class = (y_test > median_price_threshold).astype(int)\ny_test_pred_class = (y_test_pred > median_price_threshold).astype(int)\nconf_matrix = confusion_matrix(y_test_class, y_test_pred_class)\nprint(\"\\nConfusion Matrix (Test Data):\")\nprint(conf_matrix)\nprint(\"\\nClassification Report (Test Data):\")\nprint(classification_report(y_test_class, y_test_pred_class))\n# Visualize the confusion matrix\nplt.figure(figsize=(6, 5))",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "y_test_class",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "y_test_class = (y_test > median_price_threshold).astype(int)\ny_test_pred_class = (y_test_pred > median_price_threshold).astype(int)\nconf_matrix = confusion_matrix(y_test_class, y_test_pred_class)\nprint(\"\\nConfusion Matrix (Test Data):\")\nprint(conf_matrix)\nprint(\"\\nClassification Report (Test Data):\")\nprint(classification_report(y_test_class, y_test_pred_class))\n# Visualize the confusion matrix\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "y_test_pred_class",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "y_test_pred_class = (y_test_pred > median_price_threshold).astype(int)\nconf_matrix = confusion_matrix(y_test_class, y_test_pred_class)\nprint(\"\\nConfusion Matrix (Test Data):\")\nprint(conf_matrix)\nprint(\"\\nClassification Report (Test Data):\")\nprint(classification_report(y_test_class, y_test_pred_class))\n# Visualize the confusion matrix\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.title(\"Confusion Matrix (Test Data)\")",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "conf_matrix",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "conf_matrix = confusion_matrix(y_test_class, y_test_pred_class)\nprint(\"\\nConfusion Matrix (Test Data):\")\nprint(conf_matrix)\nprint(\"\\nClassification Report (Test Data):\")\nprint(classification_report(y_test_class, y_test_pred_class))\n# Visualize the confusion matrix\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.title(\"Confusion Matrix (Test Data)\")\nplt.xlabel(\"Predicted Class\")",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "mean_price",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "mean_price = df['price'].mean()\nmedian_price = df['price'].median()\nxlims = ax.get_xlim()\nylims = ax.get_ylim()\nax.text(xlims[1]*0.6, ylims[1]*0.8, f\"Mean: {mean_price:.2f}\\nMedian: {median_price:.2f}\",\n        bbox=dict(facecolor='white', alpha=0.5))\nplt.show()\n# 2️⃣ Feature vs. Price Scatter Plots with correlation coefficients\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfor i, feature in enumerate(features):",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "median_price",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "median_price = df['price'].median()\nxlims = ax.get_xlim()\nylims = ax.get_ylim()\nax.text(xlims[1]*0.6, ylims[1]*0.8, f\"Mean: {mean_price:.2f}\\nMedian: {median_price:.2f}\",\n        bbox=dict(facecolor='white', alpha=0.5))\nplt.show()\n# 2️⃣ Feature vs. Price Scatter Plots with correlation coefficients\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfor i, feature in enumerate(features):\n    row, col = divmod(i, 2)",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "xlims",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "xlims = ax.get_xlim()\nylims = ax.get_ylim()\nax.text(xlims[1]*0.6, ylims[1]*0.8, f\"Mean: {mean_price:.2f}\\nMedian: {median_price:.2f}\",\n        bbox=dict(facecolor='white', alpha=0.5))\nplt.show()\n# 2️⃣ Feature vs. Price Scatter Plots with correlation coefficients\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfor i, feature in enumerate(features):\n    row, col = divmod(i, 2)\n    sns.scatterplot(x=df[feature], y=df['price'], ax=axes[row, col], color='red')",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "ylims",
        "kind": 5,
        "importPath": "decision_tree_regressor",
        "description": "decision_tree_regressor",
        "peekOfCode": "ylims = ax.get_ylim()\nax.text(xlims[1]*0.6, ylims[1]*0.8, f\"Mean: {mean_price:.2f}\\nMedian: {median_price:.2f}\",\n        bbox=dict(facecolor='white', alpha=0.5))\nplt.show()\n# 2️⃣ Feature vs. Price Scatter Plots with correlation coefficients\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfor i, feature in enumerate(features):\n    row, col = divmod(i, 2)\n    sns.scatterplot(x=df[feature], y=df['price'], ax=axes[row, col], color='red')\n    axes[row, col].set_title(f\"{feature} vs Price\")",
        "detail": "decision_tree_regressor",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "df = pd.read_csv(\"data/Bengaluru_House_Data.csv\")\n# Data Cleaning: Remove missing values\ndf = df.dropna()\n# Keep only rows where 'total_sqft' is numeric\ndf = df[df['total_sqft'].apply(lambda x: str(x).replace('.', '').isdigit())]\ndf['total_sqft'] = df['total_sqft'].astype(float)\n# Convert 'size' to numeric by extracting the number (e.g., \"2 BHK\" or \"2 Bedroom\" -> 2)\nif 'size' in df.columns:\n    df['size'] = df['size'].str.extract(r\"(\\d+)\").astype(float)\n# Updated feature list",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "df = df.dropna()\n# Keep only rows where 'total_sqft' is numeric\ndf = df[df['total_sqft'].apply(lambda x: str(x).replace('.', '').isdigit())]\ndf['total_sqft'] = df['total_sqft'].astype(float)\n# Convert 'size' to numeric by extracting the number (e.g., \"2 BHK\" or \"2 Bedroom\" -> 2)\nif 'size' in df.columns:\n    df['size'] = df['size'].str.extract(r\"(\\d+)\").astype(float)\n# Updated feature list\nfeatures = ['total_sqft', 'bath', 'balcony', 'size']\ntarget = 'price'",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "df = df[df['total_sqft'].apply(lambda x: str(x).replace('.', '').isdigit())]\ndf['total_sqft'] = df['total_sqft'].astype(float)\n# Convert 'size' to numeric by extracting the number (e.g., \"2 BHK\" or \"2 Bedroom\" -> 2)\nif 'size' in df.columns:\n    df['size'] = df['size'].str.extract(r\"(\\d+)\").astype(float)\n# Updated feature list\nfeatures = ['total_sqft', 'bath', 'balcony', 'size']\ntarget = 'price'\n# Filter the dataframe to required columns\ndf = df[features + [target]]",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "df['total_sqft']",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "df['total_sqft'] = df['total_sqft'].astype(float)\n# Convert 'size' to numeric by extracting the number (e.g., \"2 BHK\" or \"2 Bedroom\" -> 2)\nif 'size' in df.columns:\n    df['size'] = df['size'].str.extract(r\"(\\d+)\").astype(float)\n# Updated feature list\nfeatures = ['total_sqft', 'bath', 'balcony', 'size']\ntarget = 'price'\n# Filter the dataframe to required columns\ndf = df[features + [target]]\n# Train-Test Split",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "features = ['total_sqft', 'bath', 'balcony', 'size']\ntarget = 'price'\n# Filter the dataframe to required columns\ndf = df[features + [target]]\n# Train-Test Split\nX = df[features]\ny = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale the features (XGBoost can work without scaling, but we keep it for consistency)\nscaler = StandardScaler()",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "target",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "target = 'price'\n# Filter the dataframe to required columns\ndf = df[features + [target]]\n# Train-Test Split\nX = df[features]\ny = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale the features (XGBoost can work without scaling, but we keep it for consistency)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "df = df[features + [target]]\n# Train-Test Split\nX = df[features]\ny = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale the features (XGBoost can work without scaling, but we keep it for consistency)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# ================================",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "X",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "X = df[features]\ny = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale the features (XGBoost can work without scaling, but we keep it for consistency)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# ================================\n# Train XGBoost Regressor\n# ================================",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "y = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale the features (XGBoost can work without scaling, but we keep it for consistency)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# ================================\n# Train XGBoost Regressor\n# ================================\nmodel = xgb.XGBRegressor(random_state=42, n_estimators=100, objective='reg:squarederror')",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "scaler",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# ================================\n# Train XGBoost Regressor\n# ================================\nmodel = xgb.XGBRegressor(random_state=42, n_estimators=100, objective='reg:squarederror')\nmodel.fit(X_train_scaled, y_train)\n# Predictions\ny_train_pred = model.predict(X_train_scaled)",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "X_train_scaled",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "X_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# ================================\n# Train XGBoost Regressor\n# ================================\nmodel = xgb.XGBRegressor(random_state=42, n_estimators=100, objective='reg:squarederror')\nmodel.fit(X_train_scaled, y_train)\n# Predictions\ny_train_pred = model.predict(X_train_scaled)\ny_test_pred = model.predict(X_test_scaled)",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "X_test_scaled",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "X_test_scaled = scaler.transform(X_test)\n# ================================\n# Train XGBoost Regressor\n# ================================\nmodel = xgb.XGBRegressor(random_state=42, n_estimators=100, objective='reg:squarederror')\nmodel.fit(X_train_scaled, y_train)\n# Predictions\ny_train_pred = model.predict(X_train_scaled)\ny_test_pred = model.predict(X_test_scaled)\n# Performance Metrics",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "model = xgb.XGBRegressor(random_state=42, n_estimators=100, objective='reg:squarederror')\nmodel.fit(X_train_scaled, y_train)\n# Predictions\ny_train_pred = model.predict(X_train_scaled)\ny_test_pred = model.predict(X_test_scaled)\n# Performance Metrics\ntrain_mae = mean_absolute_error(y_train, y_train_pred)\ntest_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "y_train_pred",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "y_train_pred = model.predict(X_train_scaled)\ny_test_pred = model.predict(X_test_scaled)\n# Performance Metrics\ntrain_mae = mean_absolute_error(y_train, y_train_pred)\ntest_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"XGBoost Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "y_test_pred",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "y_test_pred = model.predict(X_test_scaled)\n# Performance Metrics\ntrain_mae = mean_absolute_error(y_train, y_train_pred)\ntest_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"XGBoost Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"XGBoost Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "train_mae",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "train_mae = mean_absolute_error(y_train, y_train_pred)\ntest_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"XGBoost Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"XGBoost Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"XGBoost Regressor - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "test_mae",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "test_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"XGBoost Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"XGBoost Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"XGBoost Regressor - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler\njoblib.dump(model, \"house_price_xgboost_model.pkl\")",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "train_rmse",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"XGBoost Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"XGBoost Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"XGBoost Regressor - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler\njoblib.dump(model, \"house_price_xgboost_model.pkl\")\njoblib.dump(scaler, \"scaler.pkl\")",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "test_rmse",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"XGBoost Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"XGBoost Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"XGBoost Regressor - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler\njoblib.dump(model, \"house_price_xgboost_model.pkl\")\njoblib.dump(scaler, \"scaler.pkl\")\nprint(\"XGBoost model training complete! Saved as 'house_price_xgboost_model.pkl'.\")",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "train_r2",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "train_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"XGBoost Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"XGBoost Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"XGBoost Regressor - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler\njoblib.dump(model, \"house_price_xgboost_model.pkl\")\njoblib.dump(scaler, \"scaler.pkl\")\nprint(\"XGBoost model training complete! Saved as 'house_price_xgboost_model.pkl'.\")\n# ================================",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "test_r2",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "test_r2 = r2_score(y_test, y_test_pred)\nprint(f\"XGBoost Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"XGBoost Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"XGBoost Regressor - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler\njoblib.dump(model, \"house_price_xgboost_model.pkl\")\njoblib.dump(scaler, \"scaler.pkl\")\nprint(\"XGBoost model training complete! Saved as 'house_price_xgboost_model.pkl'.\")\n# ================================\n# Additional: Confusion Metrics for Regression",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "median_price_threshold",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "median_price_threshold = df['price'].median()\ny_test_class = (y_test > median_price_threshold).astype(int)\ny_test_pred_class = (y_test_pred > median_price_threshold).astype(int)\nconf_matrix = confusion_matrix(y_test_class, y_test_pred_class)\nprint(\"\\nConfusion Matrix (Test Data):\")\nprint(conf_matrix)\nprint(\"\\nClassification Report (Test Data):\")\nprint(classification_report(y_test_class, y_test_pred_class))\n# Visualize the confusion matrix\nplt.figure(figsize=(6, 5))",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "y_test_class",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "y_test_class = (y_test > median_price_threshold).astype(int)\ny_test_pred_class = (y_test_pred > median_price_threshold).astype(int)\nconf_matrix = confusion_matrix(y_test_class, y_test_pred_class)\nprint(\"\\nConfusion Matrix (Test Data):\")\nprint(conf_matrix)\nprint(\"\\nClassification Report (Test Data):\")\nprint(classification_report(y_test_class, y_test_pred_class))\n# Visualize the confusion matrix\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "y_test_pred_class",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "y_test_pred_class = (y_test_pred > median_price_threshold).astype(int)\nconf_matrix = confusion_matrix(y_test_class, y_test_pred_class)\nprint(\"\\nConfusion Matrix (Test Data):\")\nprint(conf_matrix)\nprint(\"\\nClassification Report (Test Data):\")\nprint(classification_report(y_test_class, y_test_pred_class))\n# Visualize the confusion matrix\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.title(\"Confusion Matrix (Test Data)\")",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "conf_matrix",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "conf_matrix = confusion_matrix(y_test_class, y_test_pred_class)\nprint(\"\\nConfusion Matrix (Test Data):\")\nprint(conf_matrix)\nprint(\"\\nClassification Report (Test Data):\")\nprint(classification_report(y_test_class, y_test_pred_class))\n# Visualize the confusion matrix\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.title(\"Confusion Matrix (Test Data)\")\nplt.xlabel(\"Predicted Class\")",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "mean_price",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "mean_price = df['price'].mean()\nmedian_price = df['price'].median()\nxlims = ax.get_xlim()\nylims = ax.get_ylim()\nax.text(xlims[1]*0.6, ylims[1]*0.8, f\"Mean: {mean_price:.2f}\\nMedian: {median_price:.2f}\",\n        bbox=dict(facecolor='white', alpha=0.5))\nplt.show()\n# 2️⃣ Feature vs. Price Scatter Plots with correlation coefficients\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfor i, feature in enumerate(features):",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "median_price",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "median_price = df['price'].median()\nxlims = ax.get_xlim()\nylims = ax.get_ylim()\nax.text(xlims[1]*0.6, ylims[1]*0.8, f\"Mean: {mean_price:.2f}\\nMedian: {median_price:.2f}\",\n        bbox=dict(facecolor='white', alpha=0.5))\nplt.show()\n# 2️⃣ Feature vs. Price Scatter Plots with correlation coefficients\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfor i, feature in enumerate(features):\n    row, col = divmod(i, 2)",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "xlims",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "xlims = ax.get_xlim()\nylims = ax.get_ylim()\nax.text(xlims[1]*0.6, ylims[1]*0.8, f\"Mean: {mean_price:.2f}\\nMedian: {median_price:.2f}\",\n        bbox=dict(facecolor='white', alpha=0.5))\nplt.show()\n# 2️⃣ Feature vs. Price Scatter Plots with correlation coefficients\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfor i, feature in enumerate(features):\n    row, col = divmod(i, 2)\n    sns.scatterplot(x=df[feature], y=df['price'], ax=axes[row, col], color='red')",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "ylims",
        "kind": 5,
        "importPath": "gradient_boosting_xgboost",
        "description": "gradient_boosting_xgboost",
        "peekOfCode": "ylims = ax.get_ylim()\nax.text(xlims[1]*0.6, ylims[1]*0.8, f\"Mean: {mean_price:.2f}\\nMedian: {median_price:.2f}\",\n        bbox=dict(facecolor='white', alpha=0.5))\nplt.show()\n# 2️⃣ Feature vs. Price Scatter Plots with correlation coefficients\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfor i, feature in enumerate(features):\n    row, col = divmod(i, 2)\n    sns.scatterplot(x=df[feature], y=df['price'], ax=axes[row, col], color='red')\n    axes[row, col].set_title(f\"{feature} vs Price\")",
        "detail": "gradient_boosting_xgboost",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "df = pd.read_csv(\"data/Bengaluru_House_Data.csv\")\n# Data Cleaning: Remove missing values\ndf = df.dropna()\n# Keep only rows where 'total_sqft' is numeric\ndf = df[df['total_sqft'].apply(lambda x: str(x).replace('.', '').isdigit())]\ndf['total_sqft'] = df['total_sqft'].astype(float)\n# Convert 'size' to numeric by extracting the number (e.g., \"2 BHK\" or \"2 Bedroom\" -> 2)\nif 'size' in df.columns:\n    df['size'] = df['size'].str.extract(r\"(\\d+)\").astype(float)\n# Updated feature list",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "df = df.dropna()\n# Keep only rows where 'total_sqft' is numeric\ndf = df[df['total_sqft'].apply(lambda x: str(x).replace('.', '').isdigit())]\ndf['total_sqft'] = df['total_sqft'].astype(float)\n# Convert 'size' to numeric by extracting the number (e.g., \"2 BHK\" or \"2 Bedroom\" -> 2)\nif 'size' in df.columns:\n    df['size'] = df['size'].str.extract(r\"(\\d+)\").astype(float)\n# Updated feature list\nfeatures = ['total_sqft', 'bath', 'balcony', 'size']\ntarget = 'price'",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "df = df[df['total_sqft'].apply(lambda x: str(x).replace('.', '').isdigit())]\ndf['total_sqft'] = df['total_sqft'].astype(float)\n# Convert 'size' to numeric by extracting the number (e.g., \"2 BHK\" or \"2 Bedroom\" -> 2)\nif 'size' in df.columns:\n    df['size'] = df['size'].str.extract(r\"(\\d+)\").astype(float)\n# Updated feature list\nfeatures = ['total_sqft', 'bath', 'balcony', 'size']\ntarget = 'price'\n# Filter dataframe to required columns\ndf = df[features + [target]]",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "df['total_sqft']",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "df['total_sqft'] = df['total_sqft'].astype(float)\n# Convert 'size' to numeric by extracting the number (e.g., \"2 BHK\" or \"2 Bedroom\" -> 2)\nif 'size' in df.columns:\n    df['size'] = df['size'].str.extract(r\"(\\d+)\").astype(float)\n# Updated feature list\nfeatures = ['total_sqft', 'bath', 'balcony', 'size']\ntarget = 'price'\n# Filter dataframe to required columns\ndf = df[features + [target]]\n# Train-Test Split",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "features = ['total_sqft', 'bath', 'balcony', 'size']\ntarget = 'price'\n# Filter dataframe to required columns\ndf = df[features + [target]]\n# Train-Test Split\nX = df[features]\ny = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale the features (LightGBM can handle unscaled data, but scaling is kept for consistency)\nscaler = StandardScaler()",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "target",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "target = 'price'\n# Filter dataframe to required columns\ndf = df[features + [target]]\n# Train-Test Split\nX = df[features]\ny = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale the features (LightGBM can handle unscaled data, but scaling is kept for consistency)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "df = df[features + [target]]\n# Train-Test Split\nX = df[features]\ny = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale the features (LightGBM can handle unscaled data, but scaling is kept for consistency)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# ================================",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "X",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "X = df[features]\ny = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale the features (LightGBM can handle unscaled data, but scaling is kept for consistency)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# ================================\n# Train LightGBM Regressor\n# ================================",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "y = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale the features (LightGBM can handle unscaled data, but scaling is kept for consistency)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# ================================\n# Train LightGBM Regressor\n# ================================\nmodel = lgb.LGBMRegressor(random_state=42, n_estimators=100)",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "scaler",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# ================================\n# Train LightGBM Regressor\n# ================================\nmodel = lgb.LGBMRegressor(random_state=42, n_estimators=100)\nmodel.fit(X_train_scaled, y_train)\n# Predictions\ny_train_pred = model.predict(X_train_scaled)",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "X_train_scaled",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "X_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# ================================\n# Train LightGBM Regressor\n# ================================\nmodel = lgb.LGBMRegressor(random_state=42, n_estimators=100)\nmodel.fit(X_train_scaled, y_train)\n# Predictions\ny_train_pred = model.predict(X_train_scaled)\ny_test_pred = model.predict(X_test_scaled)",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "X_test_scaled",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "X_test_scaled = scaler.transform(X_test)\n# ================================\n# Train LightGBM Regressor\n# ================================\nmodel = lgb.LGBMRegressor(random_state=42, n_estimators=100)\nmodel.fit(X_train_scaled, y_train)\n# Predictions\ny_train_pred = model.predict(X_train_scaled)\ny_test_pred = model.predict(X_test_scaled)\n# Model Performance Metrics",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "model = lgb.LGBMRegressor(random_state=42, n_estimators=100)\nmodel.fit(X_train_scaled, y_train)\n# Predictions\ny_train_pred = model.predict(X_train_scaled)\ny_test_pred = model.predict(X_test_scaled)\n# Model Performance Metrics\ntrain_mae = mean_absolute_error(y_train, y_train_pred)\ntest_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "y_train_pred",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "y_train_pred = model.predict(X_train_scaled)\ny_test_pred = model.predict(X_test_scaled)\n# Model Performance Metrics\ntrain_mae = mean_absolute_error(y_train, y_train_pred)\ntest_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"LightGBM Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "y_test_pred",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "y_test_pred = model.predict(X_test_scaled)\n# Model Performance Metrics\ntrain_mae = mean_absolute_error(y_train, y_train_pred)\ntest_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"LightGBM Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"LightGBM Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "train_mae",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "train_mae = mean_absolute_error(y_train, y_train_pred)\ntest_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"LightGBM Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"LightGBM Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"LightGBM Regressor - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "test_mae",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "test_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"LightGBM Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"LightGBM Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"LightGBM Regressor - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler\njoblib.dump(model, \"house_price_lightgbm_model.pkl\")",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "train_rmse",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"LightGBM Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"LightGBM Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"LightGBM Regressor - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler\njoblib.dump(model, \"house_price_lightgbm_model.pkl\")\njoblib.dump(scaler, \"scaler.pkl\")",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "test_rmse",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"LightGBM Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"LightGBM Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"LightGBM Regressor - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler\njoblib.dump(model, \"house_price_lightgbm_model.pkl\")\njoblib.dump(scaler, \"scaler.pkl\")\nprint(\"LightGBM model training complete! Saved as 'house_price_lightgbm_model.pkl'.\")",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "train_r2",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "train_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"LightGBM Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"LightGBM Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"LightGBM Regressor - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler\njoblib.dump(model, \"house_price_lightgbm_model.pkl\")\njoblib.dump(scaler, \"scaler.pkl\")\nprint(\"LightGBM model training complete! Saved as 'house_price_lightgbm_model.pkl'.\")\n# ================================",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "test_r2",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "test_r2 = r2_score(y_test, y_test_pred)\nprint(f\"LightGBM Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"LightGBM Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"LightGBM Regressor - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler\njoblib.dump(model, \"house_price_lightgbm_model.pkl\")\njoblib.dump(scaler, \"scaler.pkl\")\nprint(\"LightGBM model training complete! Saved as 'house_price_lightgbm_model.pkl'.\")\n# ================================\n# Additional: Confusion Metrics for Regression",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "median_price_threshold",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "median_price_threshold = df['price'].median()\ny_test_class = (y_test > median_price_threshold).astype(int)\ny_test_pred_class = (y_test_pred > median_price_threshold).astype(int)\nconf_matrix = confusion_matrix(y_test_class, y_test_pred_class)\nprint(\"\\nConfusion Matrix (Test Data):\")\nprint(conf_matrix)\nprint(\"\\nClassification Report (Test Data):\")\nprint(classification_report(y_test_class, y_test_pred_class))\n# Visualize the confusion matrix\nplt.figure(figsize=(6, 5))",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "y_test_class",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "y_test_class = (y_test > median_price_threshold).astype(int)\ny_test_pred_class = (y_test_pred > median_price_threshold).astype(int)\nconf_matrix = confusion_matrix(y_test_class, y_test_pred_class)\nprint(\"\\nConfusion Matrix (Test Data):\")\nprint(conf_matrix)\nprint(\"\\nClassification Report (Test Data):\")\nprint(classification_report(y_test_class, y_test_pred_class))\n# Visualize the confusion matrix\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "y_test_pred_class",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "y_test_pred_class = (y_test_pred > median_price_threshold).astype(int)\nconf_matrix = confusion_matrix(y_test_class, y_test_pred_class)\nprint(\"\\nConfusion Matrix (Test Data):\")\nprint(conf_matrix)\nprint(\"\\nClassification Report (Test Data):\")\nprint(classification_report(y_test_class, y_test_pred_class))\n# Visualize the confusion matrix\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.title(\"Confusion Matrix (Test Data)\")",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "conf_matrix",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "conf_matrix = confusion_matrix(y_test_class, y_test_pred_class)\nprint(\"\\nConfusion Matrix (Test Data):\")\nprint(conf_matrix)\nprint(\"\\nClassification Report (Test Data):\")\nprint(classification_report(y_test_class, y_test_pred_class))\n# Visualize the confusion matrix\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.title(\"Confusion Matrix (Test Data)\")\nplt.xlabel(\"Predicted Class\")",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "mean_price",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "mean_price = df['price'].mean()\nmedian_price = df['price'].median()\nxlims = ax.get_xlim()\nylims = ax.get_ylim()\nax.text(xlims[1]*0.6, ylims[1]*0.8, f\"Mean: {mean_price:.2f}\\nMedian: {median_price:.2f}\",\n        bbox=dict(facecolor='white', alpha=0.5))\nplt.show()\n# 2️⃣ Feature vs. Price Scatter Plots with correlation coefficients\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfor i, feature in enumerate(features):",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "median_price",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "median_price = df['price'].median()\nxlims = ax.get_xlim()\nylims = ax.get_ylim()\nax.text(xlims[1]*0.6, ylims[1]*0.8, f\"Mean: {mean_price:.2f}\\nMedian: {median_price:.2f}\",\n        bbox=dict(facecolor='white', alpha=0.5))\nplt.show()\n# 2️⃣ Feature vs. Price Scatter Plots with correlation coefficients\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfor i, feature in enumerate(features):\n    row, col = divmod(i, 2)",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "xlims",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "xlims = ax.get_xlim()\nylims = ax.get_ylim()\nax.text(xlims[1]*0.6, ylims[1]*0.8, f\"Mean: {mean_price:.2f}\\nMedian: {median_price:.2f}\",\n        bbox=dict(facecolor='white', alpha=0.5))\nplt.show()\n# 2️⃣ Feature vs. Price Scatter Plots with correlation coefficients\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfor i, feature in enumerate(features):\n    row, col = divmod(i, 2)\n    sns.scatterplot(x=df[feature], y=df['price'], ax=axes[row, col], color='red')",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "ylims",
        "kind": 5,
        "importPath": "gradient_boost_lightgbm",
        "description": "gradient_boost_lightgbm",
        "peekOfCode": "ylims = ax.get_ylim()\nax.text(xlims[1]*0.6, ylims[1]*0.8, f\"Mean: {mean_price:.2f}\\nMedian: {median_price:.2f}\",\n        bbox=dict(facecolor='white', alpha=0.5))\nplt.show()\n# 2️⃣ Feature vs. Price Scatter Plots with correlation coefficients\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfor i, feature in enumerate(features):\n    row, col = divmod(i, 2)\n    sns.scatterplot(x=df[feature], y=df['price'], ax=axes[row, col], color='red')\n    axes[row, col].set_title(f\"{feature} vs Price\")",
        "detail": "gradient_boost_lightgbm",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "df = pd.read_csv(\"data/Bengaluru_House_Data.csv\")\n# Data Cleaning: Remove missing values\ndf = df.dropna()\n# Keep only rows where 'total_sqft' is numeric\ndf = df[df['total_sqft'].apply(lambda x: str(x).replace('.', '').isdigit())]\ndf['total_sqft'] = df['total_sqft'].astype(float)\n# Convert 'size' to numeric by extracting the number (e.g., \"2 BHK\" or \"2 Bedroom\" -> 2)\nif 'size' in df.columns:\n    df['size'] = df['size'].str.extract(r\"(\\d+)\").astype(float)\n# Updated feature list and target",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "df = df.dropna()\n# Keep only rows where 'total_sqft' is numeric\ndf = df[df['total_sqft'].apply(lambda x: str(x).replace('.', '').isdigit())]\ndf['total_sqft'] = df['total_sqft'].astype(float)\n# Convert 'size' to numeric by extracting the number (e.g., \"2 BHK\" or \"2 Bedroom\" -> 2)\nif 'size' in df.columns:\n    df['size'] = df['size'].str.extract(r\"(\\d+)\").astype(float)\n# Updated feature list and target\nfeatures = ['total_sqft', 'bath', 'balcony', 'size']\ntarget = 'price'",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "df = df[df['total_sqft'].apply(lambda x: str(x).replace('.', '').isdigit())]\ndf['total_sqft'] = df['total_sqft'].astype(float)\n# Convert 'size' to numeric by extracting the number (e.g., \"2 BHK\" or \"2 Bedroom\" -> 2)\nif 'size' in df.columns:\n    df['size'] = df['size'].str.extract(r\"(\\d+)\").astype(float)\n# Updated feature list and target\nfeatures = ['total_sqft', 'bath', 'balcony', 'size']\ntarget = 'price'\ndf = df[features + [target]]\n# Train-Test Split",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "df['total_sqft']",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "df['total_sqft'] = df['total_sqft'].astype(float)\n# Convert 'size' to numeric by extracting the number (e.g., \"2 BHK\" or \"2 Bedroom\" -> 2)\nif 'size' in df.columns:\n    df['size'] = df['size'].str.extract(r\"(\\d+)\").astype(float)\n# Updated feature list and target\nfeatures = ['total_sqft', 'bath', 'balcony', 'size']\ntarget = 'price'\ndf = df[features + [target]]\n# Train-Test Split\nX = df[features]",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "features = ['total_sqft', 'bath', 'balcony', 'size']\ntarget = 'price'\ndf = df[features + [target]]\n# Train-Test Split\nX = df[features]\ny = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale the features (optional for tree-based methods, but included for consistency)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "target",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "target = 'price'\ndf = df[features + [target]]\n# Train-Test Split\nX = df[features]\ny = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale the features (optional for tree-based methods, but included for consistency)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "df = df[features + [target]]\n# Train-Test Split\nX = df[features]\ny = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale the features (optional for tree-based methods, but included for consistency)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# ================================",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "X",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "X = df[features]\ny = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale the features (optional for tree-based methods, but included for consistency)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# ================================\n# Train Random Forest Regressor\n# ================================",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "y = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale the features (optional for tree-based methods, but included for consistency)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# ================================\n# Train Random Forest Regressor\n# ================================\nmodel = RandomForestRegressor(random_state=42, n_estimators=100)",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "scaler",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# ================================\n# Train Random Forest Regressor\n# ================================\nmodel = RandomForestRegressor(random_state=42, n_estimators=100)\nmodel.fit(X_train_scaled, y_train)\n# Predictions\ny_train_pred = model.predict(X_train_scaled)",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "X_train_scaled",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "X_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# ================================\n# Train Random Forest Regressor\n# ================================\nmodel = RandomForestRegressor(random_state=42, n_estimators=100)\nmodel.fit(X_train_scaled, y_train)\n# Predictions\ny_train_pred = model.predict(X_train_scaled)\ny_test_pred = model.predict(X_test_scaled)",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "X_test_scaled",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "X_test_scaled = scaler.transform(X_test)\n# ================================\n# Train Random Forest Regressor\n# ================================\nmodel = RandomForestRegressor(random_state=42, n_estimators=100)\nmodel.fit(X_train_scaled, y_train)\n# Predictions\ny_train_pred = model.predict(X_train_scaled)\ny_test_pred = model.predict(X_test_scaled)\n# Compute Performance Metrics",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "model = RandomForestRegressor(random_state=42, n_estimators=100)\nmodel.fit(X_train_scaled, y_train)\n# Predictions\ny_train_pred = model.predict(X_train_scaled)\ny_test_pred = model.predict(X_test_scaled)\n# Compute Performance Metrics\ntrain_mae = mean_absolute_error(y_train, y_train_pred)\ntest_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "y_train_pred",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "y_train_pred = model.predict(X_train_scaled)\ny_test_pred = model.predict(X_test_scaled)\n# Compute Performance Metrics\ntrain_mae = mean_absolute_error(y_train, y_train_pred)\ntest_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Random Forest Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "y_test_pred",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "y_test_pred = model.predict(X_test_scaled)\n# Compute Performance Metrics\ntrain_mae = mean_absolute_error(y_train, y_train_pred)\ntest_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Random Forest Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Random Forest Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "train_mae",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "train_mae = mean_absolute_error(y_train, y_train_pred)\ntest_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Random Forest Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Random Forest Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"Random Forest Regressor - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "test_mae",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "test_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Random Forest Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Random Forest Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"Random Forest Regressor - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler\njoblib.dump(model, \"house_price_random_forest_model.pkl\")",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "train_rmse",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Random Forest Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Random Forest Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"Random Forest Regressor - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler\njoblib.dump(model, \"house_price_random_forest_model.pkl\")\njoblib.dump(scaler, \"scaler.pkl\")",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "test_rmse",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Random Forest Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Random Forest Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"Random Forest Regressor - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler\njoblib.dump(model, \"house_price_random_forest_model.pkl\")\njoblib.dump(scaler, \"scaler.pkl\")\nprint(\"Random Forest model training complete! Saved as 'house_price_random_forest_model.pkl'.\")",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "train_r2",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "train_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Random Forest Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Random Forest Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"Random Forest Regressor - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler\njoblib.dump(model, \"house_price_random_forest_model.pkl\")\njoblib.dump(scaler, \"scaler.pkl\")\nprint(\"Random Forest model training complete! Saved as 'house_price_random_forest_model.pkl'.\")\n# ================================",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "test_r2",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "test_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Random Forest Regressor - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Random Forest Regressor - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"Random Forest Regressor - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler\njoblib.dump(model, \"house_price_random_forest_model.pkl\")\njoblib.dump(scaler, \"scaler.pkl\")\nprint(\"Random Forest model training complete! Saved as 'house_price_random_forest_model.pkl'.\")\n# ================================\n# Additional: Confusion Metrics for Regression",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "median_price_threshold",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "median_price_threshold = df['price'].median()\ny_test_class = (y_test > median_price_threshold).astype(int)\ny_test_pred_class = (y_test_pred > median_price_threshold).astype(int)\nconf_matrix = confusion_matrix(y_test_class, y_test_pred_class)\nprint(\"\\nConfusion Matrix (Test Data):\")\nprint(conf_matrix)\nprint(\"\\nClassification Report (Test Data):\")\nprint(classification_report(y_test_class, y_test_pred_class))\n# Visualize the confusion matrix\nplt.figure(figsize=(6, 5))",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "y_test_class",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "y_test_class = (y_test > median_price_threshold).astype(int)\ny_test_pred_class = (y_test_pred > median_price_threshold).astype(int)\nconf_matrix = confusion_matrix(y_test_class, y_test_pred_class)\nprint(\"\\nConfusion Matrix (Test Data):\")\nprint(conf_matrix)\nprint(\"\\nClassification Report (Test Data):\")\nprint(classification_report(y_test_class, y_test_pred_class))\n# Visualize the confusion matrix\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "y_test_pred_class",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "y_test_pred_class = (y_test_pred > median_price_threshold).astype(int)\nconf_matrix = confusion_matrix(y_test_class, y_test_pred_class)\nprint(\"\\nConfusion Matrix (Test Data):\")\nprint(conf_matrix)\nprint(\"\\nClassification Report (Test Data):\")\nprint(classification_report(y_test_class, y_test_pred_class))\n# Visualize the confusion matrix\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.title(\"Confusion Matrix (Test Data)\")",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "conf_matrix",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "conf_matrix = confusion_matrix(y_test_class, y_test_pred_class)\nprint(\"\\nConfusion Matrix (Test Data):\")\nprint(conf_matrix)\nprint(\"\\nClassification Report (Test Data):\")\nprint(classification_report(y_test_class, y_test_pred_class))\n# Visualize the confusion matrix\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.title(\"Confusion Matrix (Test Data)\")\nplt.xlabel(\"Predicted Class\")",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "mean_price",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "mean_price = df['price'].mean()\nmedian_price = df['price'].median()\nxlims = ax.get_xlim()\nylims = ax.get_ylim()\nax.text(xlims[1]*0.6, ylims[1]*0.8, f\"Mean: {mean_price:.2f}\\nMedian: {median_price:.2f}\",\n        bbox=dict(facecolor='white', alpha=0.5))\nplt.show()\n# 2️⃣ Feature vs. Price Scatter Plots with Correlation Coefficients\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfor i, feature in enumerate(features):",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "median_price",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "median_price = df['price'].median()\nxlims = ax.get_xlim()\nylims = ax.get_ylim()\nax.text(xlims[1]*0.6, ylims[1]*0.8, f\"Mean: {mean_price:.2f}\\nMedian: {median_price:.2f}\",\n        bbox=dict(facecolor='white', alpha=0.5))\nplt.show()\n# 2️⃣ Feature vs. Price Scatter Plots with Correlation Coefficients\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfor i, feature in enumerate(features):\n    row, col = divmod(i, 2)",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "xlims",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "xlims = ax.get_xlim()\nylims = ax.get_ylim()\nax.text(xlims[1]*0.6, ylims[1]*0.8, f\"Mean: {mean_price:.2f}\\nMedian: {median_price:.2f}\",\n        bbox=dict(facecolor='white', alpha=0.5))\nplt.show()\n# 2️⃣ Feature vs. Price Scatter Plots with Correlation Coefficients\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfor i, feature in enumerate(features):\n    row, col = divmod(i, 2)\n    sns.scatterplot(x=df[feature], y=df['price'], ax=axes[row, col], color='red')",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "ylims",
        "kind": 5,
        "importPath": "random_forest_regressor",
        "description": "random_forest_regressor",
        "peekOfCode": "ylims = ax.get_ylim()\nax.text(xlims[1]*0.6, ylims[1]*0.8, f\"Mean: {mean_price:.2f}\\nMedian: {median_price:.2f}\",\n        bbox=dict(facecolor='white', alpha=0.5))\nplt.show()\n# 2️⃣ Feature vs. Price Scatter Plots with Correlation Coefficients\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfor i, feature in enumerate(features):\n    row, col = divmod(i, 2)\n    sns.scatterplot(x=df[feature], y=df['price'], ax=axes[row, col], color='red')\n    axes[row, col].set_title(f\"{feature} vs Price\")",
        "detail": "random_forest_regressor",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "df = pd.read_csv(\"data/Bengaluru_House_Data.csv\")\n# Data Cleaning: Remove missing values\ndf = df.dropna()\n# Keep only rows where 'total_sqft' is numeric\ndf = df[df['total_sqft'].apply(lambda x: str(x).replace('.', '').isdigit())]\ndf['total_sqft'] = df['total_sqft'].astype(float)\n# Convert 'size' to numeric by extracting the number (e.g., \"2 BHK\" or \"2 Bedroom\" -> 2)\nif 'size' in df.columns:\n    df['size'] = df['size'].str.extract(r\"(\\d+)\").astype(float)\n# Define features and target",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "df = df.dropna()\n# Keep only rows where 'total_sqft' is numeric\ndf = df[df['total_sqft'].apply(lambda x: str(x).replace('.', '').isdigit())]\ndf['total_sqft'] = df['total_sqft'].astype(float)\n# Convert 'size' to numeric by extracting the number (e.g., \"2 BHK\" or \"2 Bedroom\" -> 2)\nif 'size' in df.columns:\n    df['size'] = df['size'].str.extract(r\"(\\d+)\").astype(float)\n# Define features and target\nfeatures = ['total_sqft', 'bath', 'balcony', 'size']\ntarget = 'price'",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "df = df[df['total_sqft'].apply(lambda x: str(x).replace('.', '').isdigit())]\ndf['total_sqft'] = df['total_sqft'].astype(float)\n# Convert 'size' to numeric by extracting the number (e.g., \"2 BHK\" or \"2 Bedroom\" -> 2)\nif 'size' in df.columns:\n    df['size'] = df['size'].str.extract(r\"(\\d+)\").astype(float)\n# Define features and target\nfeatures = ['total_sqft', 'bath', 'balcony', 'size']\ntarget = 'price'\n# Filter the dataframe to contain only the required columns\ndf = df[features + [target]]",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "df['total_sqft']",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "df['total_sqft'] = df['total_sqft'].astype(float)\n# Convert 'size' to numeric by extracting the number (e.g., \"2 BHK\" or \"2 Bedroom\" -> 2)\nif 'size' in df.columns:\n    df['size'] = df['size'].str.extract(r\"(\\d+)\").astype(float)\n# Define features and target\nfeatures = ['total_sqft', 'bath', 'balcony', 'size']\ntarget = 'price'\n# Filter the dataframe to contain only the required columns\ndf = df[features + [target]]\n# Train-Test Split",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "features",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "features = ['total_sqft', 'bath', 'balcony', 'size']\ntarget = 'price'\n# Filter the dataframe to contain only the required columns\ndf = df[features + [target]]\n# Train-Test Split\nX = df[features]\ny = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale the features\nscaler = StandardScaler()",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "target",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "target = 'price'\n# Filter the dataframe to contain only the required columns\ndf = df[features + [target]]\n# Train-Test Split\nX = df[features]\ny = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "df = df[features + [target]]\n# Train-Test Split\nX = df[features]\ny = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# ================================",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "X",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "X = df[features]\ny = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# ================================\n# Train Linear Regression Model\n# ================================",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "y",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "y = df[target]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n# Scale the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# ================================\n# Train Linear Regression Model\n# ================================\nmodel = LinearRegression()",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "scaler",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# ================================\n# Train Linear Regression Model\n# ================================\nmodel = LinearRegression()\nmodel.fit(X_train_scaled, y_train)\n# Predictions\ny_train_pred = model.predict(X_train_scaled)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "X_train_scaled",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "X_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n# ================================\n# Train Linear Regression Model\n# ================================\nmodel = LinearRegression()\nmodel.fit(X_train_scaled, y_train)\n# Predictions\ny_train_pred = model.predict(X_train_scaled)\ny_test_pred = model.predict(X_test_scaled)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "X_test_scaled",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "X_test_scaled = scaler.transform(X_test)\n# ================================\n# Train Linear Regression Model\n# ================================\nmodel = LinearRegression()\nmodel.fit(X_train_scaled, y_train)\n# Predictions\ny_train_pred = model.predict(X_train_scaled)\ny_test_pred = model.predict(X_test_scaled)\n# Performance Metrics",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "model = LinearRegression()\nmodel.fit(X_train_scaled, y_train)\n# Predictions\ny_train_pred = model.predict(X_train_scaled)\ny_test_pred = model.predict(X_test_scaled)\n# Performance Metrics\ntrain_mae = mean_absolute_error(y_train, y_train_pred)\ntest_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "y_train_pred",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "y_train_pred = model.predict(X_train_scaled)\ny_test_pred = model.predict(X_test_scaled)\n# Performance Metrics\ntrain_mae = mean_absolute_error(y_train, y_train_pred)\ntest_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Linear Regression - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "y_test_pred",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "y_test_pred = model.predict(X_test_scaled)\n# Performance Metrics\ntrain_mae = mean_absolute_error(y_train, y_train_pred)\ntest_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Linear Regression - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Linear Regression - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "train_mae",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "train_mae = mean_absolute_error(y_train, y_train_pred)\ntest_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Linear Regression - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Linear Regression - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"Linear Regression - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "test_mae",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "test_mae = mean_absolute_error(y_test, y_test_pred)\ntrain_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Linear Regression - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Linear Regression - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"Linear Regression - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler\njoblib.dump(model, \"house_price_model.pkl\")",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "train_rmse",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\ntest_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Linear Regression - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Linear Regression - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"Linear Regression - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler\njoblib.dump(model, \"house_price_model.pkl\")\njoblib.dump(scaler, \"scaler.pkl\")",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "test_rmse",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\ntrain_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Linear Regression - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Linear Regression - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"Linear Regression - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler\njoblib.dump(model, \"house_price_model.pkl\")\njoblib.dump(scaler, \"scaler.pkl\")\nprint(\"Model training complete! Saved as 'house_price_model.pkl'.\")",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "train_r2",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "train_r2 = r2_score(y_train, y_train_pred)\ntest_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Linear Regression - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Linear Regression - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"Linear Regression - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler\njoblib.dump(model, \"house_price_model.pkl\")\njoblib.dump(scaler, \"scaler.pkl\")\nprint(\"Model training complete! Saved as 'house_price_model.pkl'.\")\n# ================================",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "test_r2",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "test_r2 = r2_score(y_test, y_test_pred)\nprint(f\"Linear Regression - Train MAE: {train_mae:.2f}, Test MAE: {test_mae:.2f}\")\nprint(f\"Linear Regression - Train RMSE: {train_rmse:.2f}, Test RMSE: {test_rmse:.2f}\")\nprint(f\"Linear Regression - Train R²: {train_r2:.2f}, Test R²: {test_r2:.2f}\")\n# Save Model & Scaler\njoblib.dump(model, \"house_price_model.pkl\")\njoblib.dump(scaler, \"scaler.pkl\")\nprint(\"Model training complete! Saved as 'house_price_model.pkl'.\")\n# ================================\n# Additional: Confusion Metrics for Regression",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "median_price_threshold",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "median_price_threshold = df['price'].median()\ny_test_class = (y_test > median_price_threshold).astype(int)\ny_test_pred_class = (y_test_pred > median_price_threshold).astype(int)\nconf_matrix = confusion_matrix(y_test_class, y_test_pred_class)\nprint(\"\\nConfusion Matrix (Test Data):\")\nprint(conf_matrix)\nprint(\"\\nClassification Report (Test Data):\")\nprint(classification_report(y_test_class, y_test_pred_class))\n# Visualize the confusion matrix\nplt.figure(figsize=(6, 5))",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "y_test_class",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "y_test_class = (y_test > median_price_threshold).astype(int)\ny_test_pred_class = (y_test_pred > median_price_threshold).astype(int)\nconf_matrix = confusion_matrix(y_test_class, y_test_pred_class)\nprint(\"\\nConfusion Matrix (Test Data):\")\nprint(conf_matrix)\nprint(\"\\nClassification Report (Test Data):\")\nprint(classification_report(y_test_class, y_test_pred_class))\n# Visualize the confusion matrix\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "y_test_pred_class",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "y_test_pred_class = (y_test_pred > median_price_threshold).astype(int)\nconf_matrix = confusion_matrix(y_test_class, y_test_pred_class)\nprint(\"\\nConfusion Matrix (Test Data):\")\nprint(conf_matrix)\nprint(\"\\nClassification Report (Test Data):\")\nprint(classification_report(y_test_class, y_test_pred_class))\n# Visualize the confusion matrix\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.title(\"Confusion Matrix (Test Data)\")",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "conf_matrix",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "conf_matrix = confusion_matrix(y_test_class, y_test_pred_class)\nprint(\"\\nConfusion Matrix (Test Data):\")\nprint(conf_matrix)\nprint(\"\\nClassification Report (Test Data):\")\nprint(classification_report(y_test_class, y_test_pred_class))\n# Visualize the confusion matrix\nplt.figure(figsize=(6, 5))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.title(\"Confusion Matrix (Test Data)\")\nplt.xlabel(\"Predicted Class\")",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "mean_price",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "mean_price = df['price'].mean()\nmedian_price = df['price'].median()\nxlims = ax.get_xlim()\nylims = ax.get_ylim()\nax.text(xlims[1]*0.6, ylims[1]*0.8, f\"Mean: {mean_price:.2f}\\nMedian: {median_price:.2f}\",\n        bbox=dict(facecolor='white', alpha=0.5))\nplt.show()\n# 2️⃣ Feature vs Price Scatter Plots with correlation coefficients\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfor i, feature in enumerate(features):",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "median_price",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "median_price = df['price'].median()\nxlims = ax.get_xlim()\nylims = ax.get_ylim()\nax.text(xlims[1]*0.6, ylims[1]*0.8, f\"Mean: {mean_price:.2f}\\nMedian: {median_price:.2f}\",\n        bbox=dict(facecolor='white', alpha=0.5))\nplt.show()\n# 2️⃣ Feature vs Price Scatter Plots with correlation coefficients\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfor i, feature in enumerate(features):\n    row, col = divmod(i, 2)",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "xlims",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "xlims = ax.get_xlim()\nylims = ax.get_ylim()\nax.text(xlims[1]*0.6, ylims[1]*0.8, f\"Mean: {mean_price:.2f}\\nMedian: {median_price:.2f}\",\n        bbox=dict(facecolor='white', alpha=0.5))\nplt.show()\n# 2️⃣ Feature vs Price Scatter Plots with correlation coefficients\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfor i, feature in enumerate(features):\n    row, col = divmod(i, 2)\n    sns.scatterplot(x=df[feature], y=df['price'], ax=axes[row, col], color='red')",
        "detail": "train_model",
        "documentation": {}
    },
    {
        "label": "ylims",
        "kind": 5,
        "importPath": "train_model",
        "description": "train_model",
        "peekOfCode": "ylims = ax.get_ylim()\nax.text(xlims[1]*0.6, ylims[1]*0.8, f\"Mean: {mean_price:.2f}\\nMedian: {median_price:.2f}\",\n        bbox=dict(facecolor='white', alpha=0.5))\nplt.show()\n# 2️⃣ Feature vs Price Scatter Plots with correlation coefficients\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\nfor i, feature in enumerate(features):\n    row, col = divmod(i, 2)\n    sns.scatterplot(x=df[feature], y=df['price'], ax=axes[row, col], color='red')\n    axes[row, col].set_title(f\"{feature} vs Price\")",
        "detail": "train_model",
        "documentation": {}
    }
]